{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating Colorado’s Housing Shortfall\n",
    "\n",
    "Greg Totten (Colorado State Demography Office)"
   ],
   "id": "ec2e37d2-99f6-433f-b6ea-2162e08085a7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n",
      "✔ dplyr     1.1.4     ✔ readr     2.1.5\n",
      "✔ forcats   1.0.0     ✔ stringr   1.5.1\n",
      "✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n",
      "✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n",
      "✔ purrr     1.0.4     \n",
      "── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "✖ dplyr::filter() masks stats::filter()\n",
      "✖ dplyr::lag()    masks stats::lag()\n",
      "ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "The duckplyr package is configured to fall back to dplyr when it encounters an\n",
      "incompatibility. Fallback events can be collected and uploaded for analysis to\n",
      "guide future development. By default, data will be collected but no data will\n",
      "be uploaded.\n",
      "ℹ Automatic fallback uploading is not controlled and therefore disabled, see\n",
      "  `?duckplyr::fallback()`.\n",
      "✔ Number of reports ready for upload: 54.\n",
      "→ Review with `duckplyr::fallback_review()`, upload with\n",
      "  `duckplyr::fallback_upload()`.\n",
      "ℹ Configure automatic uploading with `duckplyr::fallback_config()`.\n",
      "✔ Overwriting dplyr methods with duckplyr methods.\n",
      "ℹ Turn off with `duckplyr::methods_restore()`."
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "Attaching package: 'srvyr'\n",
      "\n",
      "The following object is masked from 'package:stats':\n",
      "\n",
      "    filter"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "Attaching package: 'scales'\n",
      "\n",
      "The following object is masked from 'package:purrr':\n",
      "\n",
      "    discard\n",
      "\n",
      "The following object is masked from 'package:readr':\n",
      "\n",
      "    col_factor"
     ]
    }
   ],
   "source": [
    "library(tidyverse)"
   ],
   "id": "9a28d6c7-5f19-413b-9045-1258318614e3"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining The Shortfall\n",
    "\n",
    "In order to estimate the total housing shortfall in Colorado, we must first define the metrics by which we are going to assess the number of housing units the state might be short.\n",
    "\n",
    "How these metrics are defined can have a significant impact on the resulting analysis. As a highly stylized example to demonstrate this concept let’s begin by using two examples to bound our estimates:\n",
    "\n",
    "1.  Every person currently residing in the state does so inside of a permanent housing unit. In this scenario we would have a relatively low estimate of the total number of necessary housing units - as what would be required is enough units to house the state’s unhoused population. In this case the estimate of number housing units might just be the estimate of the number of people in this population. However, this could be reduced by changing our requirements of housing to include any shelter - such as tents as vehicles, which would likely bring the estimated much lower.\n",
    "2.  Every current US resident who would like to live in Colorado may do so, and they will be able to do so for free. Conversely, in this scenario we might expect an estimate that is quite high, as while some people still may opt not to reside in our beautiful state (perhaps they do not particularly like sun), we could reasonably expect many Americans, perhaps into the hundreds of millions, might opt to spend no money to live in our beautiful state.\n",
    "\n",
    "In between these two estimates are a range of scenarios that might be indicative of the number of housing units which are necessary - based on the objectives we are trying to determine, and the underlying assumptions about housing preferences which underlie them. In this paper we will examine a variety of methods, based primarily on studies by other researchers, that we can apply to Colorado to determine the estimated housing shortfall in the state, under that method. In this way we will provide not so much a point estimate of the total housing shortfall, but a range of estimates which can be utilized by planners and policy makers based on their discretion with respect to the reasonableness and applicability of each method. In doing so we also hope to plan a clear, concise, explanation of the method, what objective it is attempting to solve for, and the meaning of the estimate within that context.\n",
    "\n",
    "## Data\n",
    "\n",
    "Data primarily comes from the most recent American Community Survey (“ACS”) one year estimates for Colorado, and data from the Colorado State Demography Office (“SDO”). One year ACS estimates are primarily used as the population of the state is large enough to allow for the use of such estimates. If applying similar methodologies at smaller geography levels (such as county level), it may be necessary to instead use 5 year estimates. Additionally, some methods of deriving estimates, such as by analyzing Public Use Microdata Sample (“PUMS”) data may not be possible for all methods. As such many methods determined here may only be applicable at the state level.\n",
    "\n",
    "## Examples\n",
    "\n",
    "### Harvard Joint Center for Housing Studies Blog\n",
    "\n",
    "One resource that compares four relatively recent national studies attempting to determine housing shortfalls are a January 2024 blog entry from the Harvard Joint Center for Housing Studies (“JHCS”) ([McCue and Huang 2024](#ref-mccue2024)). The four studies each utilize different methodologies and resulting estimates covering different years. The four studies are:\n",
    "\n",
    "1.  [National Association of Home Builders (NAHB) 2021](https://www.freddiemac.com/research/insight/20210507-housing-supply)\n",
    "2.  [Freddie Mac 2020](https://www.freddiemac.com/research/insight/20210507-housing-supply)\n",
    "3.  [National Association of Realtors (NAR) 2021](https://www.nar.realtor/advocacy/housing-is-critical-infrastructure)\n",
    "4.  [National Low Income Housing Coalition (NLIHC)](https://nlihc.org/gap)\n",
    "\n",
    "The following sections will provide estimates of the housing shortage in Colorado based on each of these study methodologies.\n",
    "\n",
    "### National Association of Home Builders\n",
    "\n",
    "The NAHB study estimates the national housing shortage by examining the difference in ACS vacancy rates in the current year from their long run average. This resulted in an estimated shortage of 1.5 million units.\n",
    "\n",
    "The first step is to create a time series of vacancy rates for the state with ACS data. This data is accessed from the IPUMS USA database ([Ruggles et al. 2024](#ref-ruggles2024a)) using the `ipumsr` package in R ([Greg Freedman Ellis, Derek Burk, and Finn Roberts 2024](#ref-ipumsr))."
   ],
   "id": "5cd5515a-5430-470c-90d7-b6efeec880ec"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Use of data from IPUMS USA is subject to conditions including that users should cite the data appropriately. Use command `ipums_conditions()` for more details."
     ]
    }
   ],
   "source": [
    "acs_samples <- get_sample_info(\"usa\") |>\n",
    "  filter(str_detect(name, pattern = \"20\\\\d+a$\")) |> \n",
    "  pull(name)\n",
    "\n",
    "ipums_dir <- \"data/ipums_raw/\"\n",
    "ipums_ddi <- \"usa_00081.xml\"\n",
    "file_loc <- paste0(\n",
    "  ipums_dir,\n",
    "  ipums_ddi\n",
    ")\n",
    "  if (file.exists(file_loc)) {\n",
    "    acs_ddi <- read_ipums_ddi(file_loc)\n",
    "    acs_00_23 <- acs_ddi |>\n",
    "      read_ipums_micro_list()\n",
    "  } else {\n",
    "acs_00_23 <- define_extract_micro(\n",
    "      collection = \"usa\",\n",
    "      description = \"ACS 1 year samples in Colorado of vacancy variables\",\n",
    "      samples = acs_samples,\n",
    "      variables = list(\n",
    "        var_spec(\"STATEFIP\", case_selections = \"08\"),\n",
    "        \"COUNTYFIP\",\n",
    "        \"PUMA\",\n",
    "        \"GQ\",\n",
    "        \"OWNERSHP\",\n",
    "        \"VACANCY\",\n",
    "        \"REPWT\",\n",
    "        \"AGE\",\n",
    "        \"REPWTP\"\n",
    "      ),\n",
    "      data_structure = \"hierarchical\",\n",
    "    ) |>\n",
    "      submit_extract() |>\n",
    "      wait_for_extract() |>\n",
    "      download_extract(download_dir = ipums_dir) |>\n",
    "      read_ipums_micro()\n",
    "  }"
   ],
   "id": "764f9a06-0d85-4b4c-a579-7780a6dad860"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vacancy rates are calculated based on both the `OWNERSHP` and `VACANCY` variables. Additionally the `GQ` variable is used to filter out group quarters.\n",
    "\n",
    "In order to calculate vacancy rates it is necessary to first understand what each of the values for each variable represents"
   ],
   "id": "31f83406-f9b2-4a90-9c61-676b65d5c762"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create acs_info from the DDI which includes variable information\n",
    "acs_info <- ipums_var_info(acs_ddi)\n",
    "\n",
    "# generate table with variable information\n",
    "# table will include columns {VAR}_val, and {VAR}_lbl with the value and\n",
    "# label for each variable. This is setup so tab_spanner_delim can be used to\n",
    "# separate out columns in a GT table\n",
    "acs_var_tbl <- acs_info |>\n",
    "  # only include necessary variables\n",
    "  filter(var_name %in% c('OWNERSHP', 'VACANCY', \"GQ\")) |>\n",
    "  # remove other columns\n",
    "  select(var_name, val_labels) |>\n",
    "  # unnest labels from nested columns\n",
    "  unnest(val_labels) |>\n",
    "  # group by var_name for generating row numbers to unpivot without lists\n",
    "  group_by(var_name) |>\n",
    "  # add row_numbers\n",
    "  mutate(row = row_number()) |>\n",
    "  ungroup() |> \n",
    "  # pivot wider to generate table\n",
    "  pivot_wider(\n",
    "    names_from = var_name,\n",
    "    values_from = c(val, lbl),\n",
    "    # specify order of variable then val/lbl column\n",
    "    names_glue = \"{var_name}_{.value}\",\n",
    "    # use slowest so variables are grouped together\n",
    "    names_vary = \"slowest\") |>\n",
    "  # remove row index as no longer necessary\n",
    "  select(-row) |> \n",
    "  # move GQ to end\n",
    "  relocate(starts_with(\"GQ\"), .after = last_col())\n",
    "\n",
    "# create GT table with information\n",
    "acs_var_tbl_gt <- acs_var_tbl |>\n",
    "  gt() |> \n",
    "  # create spanners based on the column separators defined above\n",
    " tab_spanner_delim(delim = \"_\") |>\n",
    "  # Replace NA values with empty strings\n",
    "  sub_missing(\n",
    "    missing_text = \"\"\n",
    "  )"
   ],
   "id": "d3ad1481-d84e-4b96-8545-b0f63890ff7a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display table\n",
    "acs_var_tbl_gt"
   ],
   "id": "29d5f97c-ded8-4108-be8c-9ada6f658585"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#tbl-pums-vars\" class=\"quarto-xref\">Table 1</a> includes the values and respective labels for each of the `OWNERSHP`, `VACANCY`, and `GQ` variables.\n",
    "\n",
    "The N/A labels associated with `val=0` for the `OWNERSHP` and `VACANCY` variables is reflective of units which are Vacant, or Occupied, respectively.\n",
    "\n",
    "Given these values we then need to establish filtering parameters for determining vacancy rates.\n",
    "\n",
    "1.  `GQ <= 2 OR GQ ==5` filter out GQ units to only included Households and Vacant Units (including with the 1990 and 2000 Additional Unit definitions)[1].\n",
    "2.  `VACANCY <=2` Remove occasional/seasonal vacant units (4-6) consistent with NAHB analysis. Remove migrant farm worker usage (7), and other vacant (9), as these should be relatively independent of overall vacancy rates. Reclassify `3` - Rented or sold but not (yet) occupied to `0` as occupied.\n",
    "3.  Leave Ownership as is.\n",
    "\n",
    "In order to broadly analyze survey data, and additionally calculate margin of error, the `srvyr` package is used. Prior to analysis a survey object must be defined based on the extracted ACS data. This survey object filters GQ units based on condition 1 above, and removes vacant units based on condition 2 above. Additionally, it reclassifies `VACANCY == 3` to `0` as occupied. Finally, `N/A` values are relabeled for each of the OWNERSHP, and VACANCY variables to reflect that these reflect Vacant and Occupied units, respectively.\n",
    "\n",
    "[1] Note to self - review these definitions to see if we want to exclude any of these groupings."
   ],
   "id": "84242186-a4d1-49ad-96a1-505ac24574aa"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Warning: `as_duckplyr_tibble()` was deprecated in duckplyr 1.0.0.\n",
      "ℹ Please use `as_duckdb_tibble()` instead."
     ]
    }
   ],
   "source": [
    "# create survey design object\n",
    "acs_hh_data <- acs_00_23$HOUSEHOLD |> \n",
    "# remove GQ units and vacant units 4-6\n",
    "  filter(\n",
    "    GQ %in% c(0,1,2,5) & \n",
    "      !(VACANCY %in% c(4:6, 7, 9))\n",
    "    ) |> \n",
    "  # reclassify 3 to 0 and 4-6 to 3\n",
    "  mutate(\n",
    "    VACANCY = lbl_relabel(\n",
    "      VACANCY, \n",
    "      0 ~.val == 3\n",
    "      ),\n",
    "    OWNERSHP = lbl_relabel(\n",
    "      OWNERSHP, \n",
    "      lbl(0, \"Vacant\") ~ .val == 0\n",
    "      )\n",
    "    ) |> \n",
    "      as_factor(levels = \"values\") |> \n",
    "      as_duckplyr_tibble()"
   ],
   "id": "cc34c5ca-317b-4b47-934b-fee5701c44e0"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then total up on an annual basis the total occupied units each for sale and for rent, as well as vacant units by for sale or for rent[1]\\[^margin of error are calculated as 1.645 \\* standard error consistent with 90% CI\\]. We additionally calculate total occupied and total vacant as the sum of each of these. Vacancy rates are then calculated as \\$ VACANT\\_{ot} \\$ for each occupancy status $o$ and year $t$. Finally we calculate the sum total of occupied and vacant units for each year[2].\n",
    "\n",
    "Once the vacancy rates are calculated, we then calculate the average vacancy rate for each year. To get an annual shortfall we then take the difference between the average vacancy rate and the current vacancy rate. Applying this difference to the total number of units for each year gives us the annual shortfall.\n",
    "\n",
    "In combining vacancy rates a `tenure` variable is created to determine if a unit is determined to be sale or rental for the purpose of calculating vacancy rates. This is set equal to the value `rent` for `OWNSHP == 2` and `VACANCY == 1`, and `own` for `OWNSHP == 1` and `VACANCY == 2`; consistent with the classifications determined above.\n",
    "\n",
    "[1] For this purpose we make the assumption that `VACANCY == 1` (For rent or sale) is for Rent, and `VACANCY ==2` (For sale only) is for sale in order to the simplify the analysis.\n",
    "\n",
    "[2] Note to self - verify that margin of error are additive"
   ],
   "id": "8b39ac33-07cb-432e-b35b-8846a9d5f106"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate vacancy\n",
    "acs_vacancy <- acs_hh_srvy |>\n",
    "  group_by(VACANCY, YEAR) |>\n",
    "  survey_count(VACANCY, name = \"vac\") |>\n",
    "  mutate(\n",
    "    vac_moe = vac_se *1.645,\n",
    "    tenure = case_when(\n",
    "      VACANCY == 1 ~ \"rent\",\n",
    "      VACANCY == 2 ~ \"own\"\n",
    "    )\n",
    "  ) |>\n",
    "  filter(!is.na(tenure)) |>\n",
    "  ungroup()\n",
    "\n",
    "# calculate occupied\n",
    "acs_occupancy <- acs_hh_srvy |>\n",
    "  group_by(OWNERSHP, YEAR) |>\n",
    "  survey_count(OWNERSHP, name = \"occ\") |>\n",
    "  mutate(\n",
    "    occ_moe = occ_se *1.645,\n",
    "    tenure = case_when(\n",
    "      OWNERSHP == 1 ~ \"own\",\n",
    "      OWNERSHP == 2 ~ \"rent\"\n",
    "    )\n",
    "  )|>\n",
    "  filter(!is.na(tenure)) |>\n",
    "  ungroup()\n",
    "\n",
    "# calculate total occupied and total vacant\n",
    "acs_combined_ov <- acs_vacancy |>\n",
    "  select(YEAR, tenure, vac, vac_moe) |>\n",
    "  left_join(acs_occupancy |>\n",
    "              select(YEAR, tenure, occ, occ_moe),\n",
    "            by = c(\"YEAR\", \"tenure\")) %>% # old style pipe needs to be used to pipe . into bind_rows\n",
    "  bind_rows(\n",
    "    summarize(\n",
    "      .,\n",
    "      tenure = \"total\",\n",
    "      across(c(vac:occ_moe), sum),\n",
    "      .by = YEAR)\n",
    "  ) |>\n",
    "  mutate(\n",
    "    total = vac + occ,\n",
    "    vac_rate = vac/total\n",
    "  ) |>\n",
    "  group_by(tenure) |>\n",
    "  mutate(avg_vac_rate = mean(vac_rate)) |>\n",
    "  ungroup() |>\n",
    "  mutate(\n",
    "    diff_from_avg = avg_vac_rate - vac_rate,\n",
    "    shortfall = diff_from_avg * total)\n",
    "\n",
    "current_shortfall <- acs_combined_ov |>\n",
    "  filter(YEAR == 2023) |>\n",
    "  select(-YEAR) |>\n",
    "  mutate(tenure = str_to_title(tenure)) |>\n",
    "  gt() |>\n",
    "  fmt_number(c(vac:total, shortfall), decimals = 0) |>\n",
    "  fmt_percent(c(vac_rate:diff_from_avg)) |>\n",
    "  cols_label(\n",
    "    tenure = \"Tenure\",\n",
    "    vac = \"Vacant\",\n",
    "    vac_moe = \"Margin of Error\",\n",
    "    occ = \"Occupied\",\n",
    "    occ_moe = \"Margin of Error\",\n",
    "    total = \"Total\",\n",
    "    vac_rate = \"Vacancy Rate\",\n",
    "    avg_vac_rate = \"Average Vacancy Rate\",\n",
    "    diff_from_avg = \"Difference from Average\",\n",
    "    shortfall = \"Shortfall\"\n",
    "  ) |>\n",
    "  cols_align(\"center\")"
   ],
   "id": "0654cffc-3d12-4163-8308-d427c713a3a1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_shortfall\n",
    "# define get_shortfall function to return shortfall based on tenure and format data\n",
    "extract_shortfall <- function (ten_type) {\n",
    "  current_shortfall |>\n",
    "    fmt_number(decimals = 1, suffixing = \"K\") |>\n",
    "    extract_cells(shortfall, rows = tenure == ten_type)\n",
    "}"
   ],
   "id": "f12dda8a-e05e-45cd-9c01-9dd716779bec"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#tbl-nahb-shortfall\" class=\"quarto-xref\">Table 2</a> contains the calculated shortfall for 2023 using the NAHB methodology. Using this methodology shortfalls of 15.4K units for rent and 13.5K units for ownership are determined, for a total shortfall of 27.7K[1].\n",
    "\n",
    "### Freddie Mac\n",
    "\n",
    "Freddie Mac determines the Target Housing Stock `k*` as a function of target number of households `hh*`, and target vacancy rate `v*`, as provided in <a href=\"#eq-freddie-mac-housing-units\" class=\"quarto-xref\">Equation 1</a>.\n",
    "\n",
    "<span id=\"eq-freddie-mac-housing-units\">$$\n",
    "k^* = {{hh^*}\\over{1-v^*}}\n",
    " \\qquad(1)$$</span>\n",
    "\n",
    "Target households are based on target headship rates according to the methods used in the 2018 Freddie Mac analysis. This analysis calculates target households based on 5 year age groups from the 1994-2018 Current Population Survey-Annual Social and Economic Supplement for target number of households $hh^*$, based on population $pop_i$ and headship rate $hr_i^*$ as provided in <a href=\"#eq-freddie-mac-headship-rate\" class=\"quarto-xref\">Equation 2</a>.\n",
    "\n",
    "<span id=\"eq-freddie-mac-headship-rate\">$$ \n",
    "{hh^*}= \\sum_{i=15}^{65+}pop_i^*hr_i^*\n",
    " \\qquad(2)$$</span>\n",
    "\n",
    "In their analysis the target headship rate is adjusted based on factors for housing costs, income, and employment, adjusting for the contribution of each using a Oaxaca-Blinder decomposition to determine the relative contribution of each factor. ([Khater et al. 2018](#ref-khater2018))\n",
    "\n",
    "In this analysis we simplify the target headship rate to be the average headship rate of the population from 2000-2023, based on our dataset above. We calculate these headship rates by similarly bucketing households based on 5 year age groups from 15-19 to 65+ and calculating the headship rate for each group, where headship rate in year $t$, $hr_{it}$, is calculated as the number of households with a head of household in age group $i$ divided by the total number of households in age group $i$, as provided in <a href=\"#eq-headship-rate\" class=\"quarto-xref\">Equation 3</a>. We then calculate the average headship rate for each group across the years 2000-2023, which is used as the target headship rate.\n",
    "\n",
    "<span id=\"eq-headship-rate\">$$\n",
    "hr_{it} = {{hh_{it}}\\over{pop_{it}}}\n",
    " \\qquad(3)$$</span>\n",
    "\n",
    "[1] Note: the Total shortfall is less than the sum of the own and vacant shortfalls due to differences as vacancy rates are determined by tenure."
   ],
   "id": "17a9f5e1-f004-4406-8d82-ef91e1046aa4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate headship rates for each age group for each year from 2000-2023\n",
    "acs_hr_data <- acs_00_23$PERSON |>\n",
    "  zap_labels(AGE) |>\n",
    "  as_factor() |>\n",
    "  as_duckplyr_tibble() |>\n",
    "  # join GQ data from household level to person level\n",
    "  left_join(acs_hh_data |>\n",
    "              select(YEAR, SERIAL, GQ), by = c(\"YEAR\", \"SERIAL\")) |>\n",
    "  filter(GQ %in% c(1, 2, 5)) |>\n",
    "  # create age bins\n",
    "  mutate(\n",
    "    # generate age breaks for cuts\n",
    "    age_bin = cut(\n",
    "      AGE,\n",
    "      breaks = c(15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, Inf),\n",
    "      right = FALSE\n",
    "    ),\n",
    "    # flag head of household\n",
    "    head_of_household = ifelse(PERNUM == 1, 1, 0)\n",
    "  )\n",
    "\n",
    "acs_hr_srvy <- acs_hr_data |>\n",
    "  # create survey object from acs_hr_data dataframe\n",
    "  as_survey_design(\n",
    "    weight = PERWT,\n",
    "    repweights = matches(\"REPWTP[0-9]+\"),\n",
    "    type = \"ACS\",\n",
    "    mse = TRUE\n",
    "  )\n",
    "\n",
    "# calculate headship rates for each age group for each year from 2000-2023\n",
    "acs_hr_totl_persons <- acs_hr_srvy |>\n",
    "  survey_count(YEAR, age_bin, name = \"total_persons\")\n",
    "\n",
    "acs_hr_hh_heads <- acs_hr_srvy |>\n",
    "  filter(PERNUM == 1) |>\n",
    "  survey_count(YEAR, age_bin, name = \"total_hh\")\n",
    "\n",
    "calc_headship_rates <- function(end_year) {\n",
    "  acs_hr_hh_heads |>\n",
    "    left_join(acs_hr_totl_persons, by = c(\"YEAR\", \"age_bin\")) |>\n",
    "    mutate(hr = total_hh / total_persons) |>\n",
    "    group_by(age_bin) |>\n",
    "    mutate(target_hr = mean(hr[YEAR <= end_year])) |>\n",
    "    ungroup() |>\n",
    "    mutate(target_hh = target_hr * total_persons,\n",
    "           missing_hh = target_hh - total_hh) %>%\n",
    "    bind_rows(\n",
    "      summarize(\n",
    "        .,\n",
    "        age_bin = \"total\",\n",
    "        across(c(\n",
    "          total_hh:total_persons_se, target_hh, missing_hh\n",
    "        ), sum),\n",
    "        hr = total_hh / total_persons,\n",
    "        target_hr = target_hh / total_persons,\n",
    "        .by = YEAR\n",
    "      )\n",
    "    ) |>\n",
    "    mutate(end_year = end_year, .before = 1)\n",
    "}\n",
    "\n",
    "acs_headship_rates <- calc_headship_rates(2015)"
   ],
   "id": "433d1014-6cfd-4ecf-baa7-d5d83e5ad371"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this analysis we find that the target number of households based on target headship rates is extremely sensitive to the end year of the target period. To demonstrate this we run the analysis based on end years of 2010, 2015, and 2020, showing the results for the “total” age_bin."
   ],
   "id": "6361a9ce-0360-435c-b337-d1ec435a482d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headship_rates_by_end_year <-\n",
    "  map(c(2010, 2015, 2020), calc_headship_rates) |>\n",
    "  bind_rows() |>\n",
    "  filter(age_bin == \"total\" & YEAR == 2023) |>\n",
    "  select(-YEAR, -age_bin) |>\n",
    "  gt() |>\n",
    "  fmt_number(!end_year, decimals = 0) |>\n",
    "  fmt_percent(hr:target_hr) |>\n",
    "  cols_align(\"center\") |>\n",
    "  cols_label(\n",
    "    end_year = \"End Year\",\n",
    "    total_persons = \"Total Persons\",\n",
    "    total_hh = \"Total Households\",\n",
    "    target_hh = \"Target Households\",\n",
    "    missing_hh = \"Missing Households\",\n",
    "    hr = \"Headship Rate\",\n",
    "    target_hr = \"Target Headship Rate\",\n",
    "    total_hh_se = \"Standard Error\",\n",
    "    total_persons_se = \"Standard Error\"\n",
    "  )\n",
    "\n",
    "headship_rates_by_end_year"
   ],
   "id": "53fb3144-19d4-422f-9c27-28ef97c1df76"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is largely driven by the large increase in headship rates beginning around 2006, as seen in <a href=\"#fig-headship-rates\" class=\"quarto-xref\">Figure 1</a>."
   ],
   "id": "20b01186-0696-4c36-a480-158c293d3234"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {},
     "data": {}
    }
   ],
   "source": [
    "acs_headship_rates |> \n",
    "  filter(age_bin == \"total\") %>%\n",
    "  bind_rows(\n",
    "    expand_grid\n",
    "    (YEAR = 2000:2023,\n",
    "      summarize(\n",
    "        .,\n",
    "        age_bin = \"avg\",\n",
    "        hr = mean(hr)\n",
    "        )\n",
    "      )\n",
    "    ) |> \n",
    "  ggplot(\n",
    "    aes(\n",
    "      x = YEAR, \n",
    "      y = hr, \n",
    "      color = age_bin\n",
    "      )\n",
    "    ) +\n",
    "  geom_line() +\n",
    "  scale_y_continuous(\n",
    "    labels = label_percent()\n",
    "  ) +\n",
    "  labs(\n",
    "    x = \"Year\",\n",
    "    y = \"Headship Rate\",\n",
    "    color = \"Overall Headship Rate\"\n",
    "  ) +\n",
    "  scale_color_discrete(\n",
    "    labels = c(\n",
    "      \"avg\" = \"2000-2023 Average\",\n",
    "      \"total\" = \"Annual\"\n",
    "    )\n",
    "  )"
   ],
   "id": "cell-fig-headship-rates"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### National Association of Realtors\n",
    "\n",
    "This uses the decline in building rates during the 2000s relative to the long term averages between 1968 and 2000 to determine the shortfall in housing from the supply side. This method was not recreated due to the inherent underlying assumptions. In particular, growth rates are not necessarily linear over time, and this is particularly the case with rapidly growing states. Colorado in particular was undergoing rapid urbanization and it is not necessarily safe to assume that growth of this style would continue.\n",
    "\n",
    "### National Low Income Housing Coalitition (NLIHC)\n",
    "\n",
    "This calculates the housing gap based on the difference between households by AMI (extremely low-income, very low-income, low-income, middle-income, or above median income), based on the applicable HUD AMI. Housing Units were separately categorized into income necessary to rent them, based on spending more than 30% of their income on housing costs (regardless of the actual income of the household occupying that housing unit). Finally they examined the extent to which households in each AMI group resided in a unit which was affordable to that household. ([“The Gap - a Shortage of Affrodable Homes” 2024](#ref-thegap2024))\n",
    "\n",
    "While this methodology is similar to the method SDO is currently working as part of its Housing Needs Assessments there is no need to recreate the table directly, as NLIHC provides state level results for all states, including [Colorado](https://nlihc.org/gap/state/co), based on 2022 ACS data.\n",
    "\n",
    "Based on their methodology NLIHC finds Colorado to be short 119,782 housing units at the Extremely Low Income (0 to 30% of Area Median Income), and 165,053 units for households at or below 50% AMI (including those who were classified as Extremely Low Income. While statewide they find that there are 101 Affordable and Available Rental Units per 100 Households for those At or Below 100% AMI, there are only 27 and 44 units Affordable and Available to those at or below the 30% and 50% AMI levels, respectively. Similarly they find that for households which are in the 0-30%, and 31-50% AMI bands, 88% and 83% units, respectively are Cost Burdened, while only 22% of units between 81 and 100% AMI are. ([“Gap Report: Colorado \\| National Low Income Housing Coalition,” n.d.](#ref-gaprepo))\n",
    "\n",
    "One important footnote to the NLIHC study, however, is that the units identified are not necessarily new housing units which must be built. Rather they indicate households that may reside in housing units already, but for which the cost may be unaffordable. This distinction is important because the housing already exists, and the objective then is to determine a method for making these units affordable to these families, which can occur in different ways, including by subsidizing rents for residents to bridge the gap between 30% of their income and the market rent being charged on their unit. Additionally, because housing prices are determined on the margins, each additional housing unit in theory pushes down housing prices by some incremental amount, holding demand equal. Therefore the number of units necessary to push prices down to a level which becomes affordable to residents at these costs is not necessarily equal to the total number of households experience affordability problems, and, in fact, may be significantly higher or lower depending on these effects and the manner to which lower rents filter down through the housing stock.\n",
    "\n",
    "“Gap Report: Colorado \\| National Low Income Housing Coalition.” n.d. <https://nlihc.org/gap/state/co>.\n",
    "\n",
    "Greg Freedman Ellis, Derek Burk, and Finn Roberts. 2024. *Ipumsr: An r Interface for Downloading, Reading, and Handling IPUMS Data*. <https://tech.popdata.org/ipumsr/>.\n",
    "\n",
    "Khater, Sam, Len Kiefer, Ajita Atreya, and Venkataramana Yanamandra. 2018. “The Major Challenge of Inadequate U.S. Housing Supply - Freddie Mac.” <https://www.freddiemac.com/research/insight/20181205-major-challenge-to-u.s.-housing-supply>.\n",
    "\n",
    "McCue, Daniel;, and Sophie Huang. 2024. “Estimating the National Housing Shortfall \\| Joint Center for Housing Studies.” <https://www.jchs.harvard.edu/blog/estimating-national-housing-shortfall>.\n",
    "\n",
    "Ruggles, Steven, Sarah Flood, Matthew Sobek, Daniel Backman, Annie Chen, Grace Cooper, Stephanie Richards, Renae Rodgers, and Megan Schouweiler. 2024. “IPUMS USA: Version 15.0.” Minneapolis, MN: IPUMS. <https://doi.org/10.18128/D010.V15.0>.\n",
    "\n",
    "“The Gap - a Shortage of Affrodable Homes.” 2024."
   ],
   "id": "91e32b94-d37f-4521-857b-e00bef058d4a"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
