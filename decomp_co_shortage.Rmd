---
title: "Colorado Housing Shortage"
output: html_document
date: "2025-04-28"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Colorado and Housing Shortages  

- Colorado has been growing and growing quickly
  - 6th fastest growing state between 2010 and 2020
- Housing production has lagged behind population growth
- Strain on the housing market and household formation
- households are not forming
- cost of housing is increasing
- How can we quantify the housing shortage?
- [Brookings](https://www.brookings.edu/articles/make-it-count-measuring-our-housing-supply-shortage/) review of housing shortage methodologies

## Putting a Number to Colorado's Housing Shortage 

The State Demography Office (SDO) at the Colorado Department of Local Affairs (DOLA) has been tasked with quantifying the housing shortage in Colorado. While a number of methodologies for quantifying housing shortages exist, the SDO's preferred method is an approach which captures

  - The relationship between population composition and household formations
  - The relationship between housing cost burden and household formations

Our approach is modeled after the methodology employed by Up for Growth to estimate Housing Underproduction. The primary formula for housing underprodcution is as follows.


![Hosuing Needs Breakdown](https://upforgrowth.org/wp-content/uploads/2022/09/Recurso-13@4x-100-1536x326.jpg)

Here housing underproduction is a function of 6 variables

  - Households
  - Missing Households
  - Target Vacancy Rate
  - Total Housing Units
  - 2nd and Vacation Units
  - Uninhabitable Units
  
To get values for these variables we will utilize the 2023 ACS microdata. We will access this data through the IPUMS service for ease of use. First, lets start with the variables on the right most side of the equation as they are more easily calculated. First, we grab our sample of housing data from the ACS micro data. From this sample, we calculate the Total Housing Units as the sum of each observation in Colorado's Household Weight.

```{r}
library(tidyverse)
library(ipumsr)
library(survey)
library(spatstat.univar)

housing_df <- read_ipums_micro("./data/ipums_raw/usa_00064.xml") %>%
  # need to remove group quarters
  filter(!(GQ %in% c(3, 4))) %>%
  # define seasonal housing
  mutate(SEASONAL = VACANCY == 4) %>%
  # define uninhabitable housing
  mutate(UNIHABITABLE = (KITCHEN == 1 | PLUMBING == 10) & VACDUR >= 7) %>%
  # define Vacancy
  mutate(VACANT = VACANCY != 0)
    

CO_HOUSING_UNITS <- housing_df %>%
  filter(STATEFIP == 8) %>%
  pull(HHWT) %>%
  sum()
```

From the survey data we find that in 2023 there were a total of `r prettyNum(CO_HOUSING_UNITS, big.mark = ",")`. Next we will want to calculate the number of second and seasonal homes. ACS survey data has a response which directly corresponds to this which is homes that are "For seasonal, recreational or other occasional use". This is also what the State of Oregon uses for their own [housing needs analysis](https://www.oregon.gov/das/oea/Documents/OHNA-Methodology-Report-2024.pdf) which closely follows the Up for Growth Methodology. For uninhabitable housing we again follow the state of Oregon's approach using houses which either have no kitchen or lack complete plumbing and which have been vacant for over 12 months.

```{r}
CO_SEASONAL_HOUSING <- housing_df %>%
  filter(STATEFIP == 8 & SEASONAL) %>%
  pull(HHWT) %>%
  sum()

CO_UNIHABITABLE_HOUSING <- housing_df %>%
  filter(STATEFIP == 8 & UNIHABITABLE) %>%
  pull(HHWT) %>%
  sum()
```

Using these definitions we find that Colorado has `r prettyNum(CO_SEASONAL_HOUSING, big.mark = ",")` seasonal housing units and `r prettyNum(CO_UNIHABITABLE_HOUSING, big.mark = ",")` uninhabitable housing units. The table below shows how the distribution of these housing types differs between Colorado and the US as a whole. We can see that relative to the US, Colorado has more 2nd and vacation house, but less uninhabitable housing.

```{r}
housing_df %>%
  mutate(HOUSINGTYPE = case_when(
    SEASONAL ~ "Seasonal",
    UNIHABITABLE ~ "Uninhabitable",
    TRUE ~ "Remaining"
  )) %>%
  group_by(HOUSINGTYPE) %>%
  summarize(USHH = sum(HHWT), .groups = "drop") %>%
  mutate(USHH = str_c(sprintf("%.2f", USHH/sum(USHH)*100), "%")) %>%
  left_join(
    housing_df %>%
      filter(STATEFIP == 8) %>% 
      mutate(HOUSINGTYPE = case_when(
        SEASONAL ~ "Seasonal",
        UNIHABITABLE ~ "Uninhabitable",
        TRUE ~ "Remaining"
      )) %>%
      group_by(HOUSINGTYPE) %>%
      summarize(COHH = sum(HHWT), .groups = "drop") %>%
      mutate(COHH = str_c(sprintf("%.2f", COHH/sum(COHH)*100), "%")),
    by = "HOUSINGTYPE"
  ) %>%
  rename(US = USHH, COLORADO = COHH)

```

Looking at the remaining housing stock that is neither a vacation home or uninhabitable, we can look at the vacancy rate in Colorado and the United States. Here we see that as of 2023, Colorado has a lower vacancy rate than the US as whole. 

```{r}
housing_df %>%
  filter(!(SEASONAL | UNIHABITABLE)) %>% 
  mutate(HOUSINGTYPE =  if_else(VACANT, "Vacant", "Occupied")) %>%
  group_by(HOUSINGTYPE) %>%
  summarize(USHH = sum(HHWT), .groups = "drop") %>%
  mutate(USHH = str_c(sprintf("%.2f", USHH/sum(USHH)*100), "%")) %>%
  left_join(
    housing_df %>%
      filter(STATEFIP == 8) %>% 
      filter(!(SEASONAL | UNIHABITABLE)) %>% 
      mutate(HOUSINGTYPE =  if_else(VACANT, "Vacant", "Occupied")) %>%
      group_by(HOUSINGTYPE) %>%
      summarize(COHH = sum(HHWT), .groups = "drop") %>%
      mutate(COHH = str_c(sprintf("%.2f", COHH/sum(COHH)*100), "%")),
    by = "HOUSINGTYPE"
  ) %>%
  rename(US = USHH, COLORADO = COHH)

```

With all of the portions of the right most part of the equation accounted for we can move to the left part of the equation, the target number of housing units. We first look at vacancy rate. Vacancy rate here refers to the desired rate of vacancy among housing units that are neither used as second/vacation homes or are uninhabitable. Any healthy housing market should have a measurable vacancy rate as housing units transition in and out of the housing market. Keeping with the original up for growth study, we opt for a vacancy rate of 5%.

Next we calculate households, which again, is straight forward using the ACS data. We simply select the households which are not vacant in the housing survey and sum their weights to get the appropriate count for households in Colorado.

```{r}
VACANCY_RATE <- .05

CO_HOUSEHOLDS <- housing_df %>%
  filter(STATEFIP == 8 & VACANCY == 0) %>%
  pull(HHWT) %>%
  sum()
```

We arrive at an estimate of `r prettyNum(CO_HOUSEHOLDS, big.mark = ",")` households in Colorado. 

The last part of the equation is missing households. Missing households here refers to the households that have not formed in a market compared to an a counterfactual market. The most common way of calculating this value is to have a target headship rate by age for your study population and to calculate how different the headship rate is from the observed population. The following formula shows how this is calculated.

$$
\sum_{\substack{i = 15} \\ \text{step }5}^{65} \text{HR}^*_{[i, i+5)} * \text{POP}_{[i, i+5)} - \text{HH}_{[15, 20)}
$$


In this formula $\text{HR}^*_{[15, 20)$ would be the target headship rate of individuals aged 15 to 19, $\text{POP}^*_{[15, 20)$ is the population aged 15 to 19 in the study, and $\text{HH}^*_{[15, 20)$ is the number of households headed by individuals aged 15 to 19 in the study. The population and number of households by age are, once again, easy to obtain from the survey data. The target headship rate, however, is conceptual, and a decision must be made about what that target should be. A common target used in studies has been the headship rate observed in the year 2000 which reflects ["a housing market that was more in balance"](https://www.oregon.gov/das/oea/Documents/OHNA-Methodology-Report-2024.pdf). To see how much headship rates have changed over time we switch to using the person frame ACS as opposed to the housing frame data. The person frame data allows us to look at people and get their characteristics. Most notably here we are interested in looking at survey respondents age and whether they are the head of household. We will do this for both the 2023 ACS as well as the 2000 Census to see how much headsip rates have changed.  

```{r}

# this is our data frame we use for inflation adjusting calculations
cpi_df <- "data/CPIAUCSL.csv" %>%
  read_csv(col_types = cols()) %>% 
  mutate(YEAR = year(observation_date)) %>%
  group_by(YEAR) %>%
  summarize(cpi = mean(CPIAUCSL), .groups = "drop") %>%
  mutate(adj_factor = first(cpi[YEAR == 2023])/cpi)

hh_df <- read_ipums_micro("./data/ipums_raw/usa_00063.xml") %>%
    # we want to filter out the group quarter population and say that
    # their impact on the housing market is exogenous to other factors
    filter(GQ %in% c(0,1,2,5)) %>%
    # recode missing codes to either missing or zero
    mutate(HHINCOME = if_else(HHINCOME == 9999999, 0, HHINCOME)) %>%
    mutate(OWNCOST = if_else(OWNCOST == 99999, 0, OWNCOST)) %>%
    mutate(INCTOT = if_else(INCTOT == 9999999, NA_integer_, INCTOT)) %>%
    mutate(HOUSINGCOST = case_when(
        OWNERSHP == 1 ~ OWNCOST,
        OWNERSHP == 2 ~ RENTGRS,
        TRUE ~ NA_integer_
    )) %>%
    # income totals are NA for most people 15 and younger so lets set their
    # income to 0
    mutate(INCTOT = if_else(is.na(INCTOT) & AGE <=15, 0, INCTOT)) %>%
    # inflation adjust our monetary values
    left_join(cpi_df, by = "YEAR") %>%
    mutate(HOUSINGCOST = HOUSINGCOST*adj_factor) %>%
    mutate(HHINCOME = HHINCOME*adj_factor) %>%
    mutate(INCTOT = INCTOT*adj_factor) %>%
    mutate(FTOTINC = FTOTINC*adj_factor) %>%
    # recode headship to binary
    mutate(HEADSHIP = RELATE == 1) %>%
    # put age groups into five year bins
    mutate(AGEGROUP = cut(
        AGE, c(0, seq(15, 65, 5), Inf),  include.lowest = TRUE, right = FALSE)
        ) %>%
    # for maths sake INCTOT and HOUSING cost will be set to 1 when less than
    # this means we treat every one with income loss as having 1 income
    # not a big deal for housing cost which moves from 0 to 1
    mutate(INCTOT = if_else(INCTOT < 1, 1, INCTOT)) %>%
    mutate(HOUSINGCOST = if_else(HOUSINGCOST < 1, 1, HOUSINGCOST)) %>%
    # calculate housing cost ratio 
    mutate(HCOSTRATIO = HOUSINGCOST/(INCTOT)*12)

(co_hr_table <- hh_df %>%
  filter(STATEFIP == 8, AGE >= 15) %>%
  group_by(AGEGROUP, YEAR) %>%
  summarise(HEADSHIP = weighted.mean(HEADSHIP, PERWT), .groups = "drop") %>%
  pivot_wider(names_from = YEAR, values_from = HEADSHIP))
```

Looking at the table above we see that almost every age group has a lower headship rate in 2023 compared to 2020. We can plug in these values for $\text{HR}^*$ to finish the last piece of the puzzle in calculating housing underproduction. 

```{r}
analysis_year <- 2023
baseline_year <- 2000
minimum_age <- 20
maximum_age <- 199
```


```{r}
simple_target_hh_df <- hh_df %>%
  filter(STATEFIP == 8, AGE >= 15, YEAR == 2000) %>%
  group_by(AGEGROUP) %>%
  summarise(NEWHH = weighted.mean(HEADSHIP, PERWT), .groups = "drop") %>%
  right_join(
    hh_df %>%
      filter(STATEFIP == 8, AGE >= 15, YEAR == 2023),
    by = "AGEGROUP"
  ) %>%
  group_by(AGEGROUP) %>%
  summarise(
    NEWHH = sum(NEWHH*PERWT),
    HH = sum(HEADSHIP*PERWT),
    .groups = "drop") %>%
  mutate(MISSINGHH = NEWHH - HH)

SIMPLE_MISSING_HH <- sum(simple_target_hh_df$MISSINGHH)

SIMPLE_UNDERPOD <- (sum(simple_target_hh_df$MISSINGHH) + CO_HOUSEHOLDS) /
  (1 - VACANCY_RATE) -
  (CO_HOUSING_UNITS - CO_SEASONAL_HOUSING - CO_UNIHABITABLE_HOUSING)
```

From these calculations we find that Colorado has `r prettyNum(round(SIMPLE_MISSING_HH ), big.mark = ",")` missing households which leads to a housing underproduction count of `r prettyNum(round(SIMPLE_UNDERPOD), big.mark = ",")` units. Note that this value is almost identical to the value published by the [Up for Growth 2023 analysis](https://upforgrowth.org/apply-the-vision/2023-housing-underproduction/), 101,000 units. This should be unsurprising given that we have followed their methodology almost exactly. 

This is just the total number of missing households and housing underproduction but we can further breakdown missing households by age to see how many missing groups are present by age. The table below shows the missing households by age. We can see that a shockingly large number of the missing households, almsot 40,000, are found in the age group of 65 and older. The fact that this age group is driving a large portion of the missing households should raise some concerns about this methodology. 

```{r}
simple_target_hh_df
```

In addition to this abnormality, the use of a past headship rate is somewhat unsatisfying. We know that headship rates are impacted by a number of factors such as housing cost, income, size of households, education levels, number of dependents, etc. As these factors change we would expect the headship rates to also shift. In addition a factor that we are most interested in for housing shortage is the relationship between cost burden of housing and the shortage of formed households. What we would like to do is to say how many household would form if the housing burden was lower. Lets take a look at the heads of household both in 2023 and in 2000 and see how much of their housing cost compares to their gross income. The table below shows these values and as we can see the share of the population who spends 0-35% of their monthly gross income on housing costs is shrinking while the share that spends more than 65% is increasing. In short people are spending more of their income on housing over time.

```{r}
hh_df %>%
  filter(YEAR == 2000 | YEAR == 2023) %>%
  filter(RELATE == 1 & STATEFIP == 8) %>%
  mutate(HCOSTQ = cut(
    HCOSTRATIO, c(0, .35, .60, Inf), labels = c("0-35%", "35-60%", ">60%"))) %>%
  group_by(YEAR, HCOSTQ) %>%
  summarize(P = sum(HHWT), .groups = "drop_last") %>%
  mutate(P = P/sum(P)*100) %>%
  ungroup() %>%
  pivot_wider(names_from = YEAR, values_from = P)
```

One way we could build a headship rate counterfactual is by saying would would the headship rate be today if housing costs were more similar to what they were in 2000. This is an improvement in that we can now capture the relationship between housing costs and headship rate, however, it still ignores the relationship between many other variables and headship rates which have changed over time. A way to account for both changing housing cost burden and other variables exists in the 3-way Kitigawa or Oaxaca-Blinder [decomposition](https://giacomovagni.com/blog/2023/oaxaca/) method. This methodology has been used in several other housing studies, such as those done by [Freddie Mac](https://www.freddiemac.com/research/insight/20181205-major-challenge-to-u.s.-housing-supply) and [Brookings](https://www.brookings.edu/articles/make-it-count-measuring-our-housing-supply-shortage/), and allow an analyst to isolate the impact of a single variable on an outcome by shifting that variables value to something it had resembled previously. 

## The housing burden effect

$Y$ is the headship status and $X$ is a set of explanatory variables.

$$
Y_{\text{baseline}} \sim \text{Binomial}(\theta_{\text{baseline}}) \\
\text{logit}(\theta_{\text{baseline}}) = \zeta_\text{baseline} X_\text{baseline}^{\text{Housing Burden}} + \boldsymbol{\beta}_\text{baseline} \boldsymbol{X}_\text{baseline} \\
Y_{\text{current}} \sim \text{Binomial}(\theta_{\text{current}}) \\
\text{logit}(\theta_{\text{current}}) = \zeta_\text{current} X_\text{current}^{\text{Housing Burden}} + \boldsymbol{\beta}_\text{current} \boldsymbol{X}_\text{current}
$$

## Housing Cost Counterfactual

$$
\text{logit}(\theta_{\text{counterfactual}}) = \zeta_\text{current} X_\text{baseline}^{\text{Housing Burden}} + \boldsymbol{\beta}_\text{current} \boldsymbol{X}_\text{current}
$$

Note for the counter factual that this change is equivalent to adding the endowment or explained effect of the decomposition for housing cost to $Y_{\text{current}}$. By applying the counterfactual prediction to each observation in our dataset we can then arrive at a new $\text{HR}^*$ which is driven by changing housing cost burden. The table below shows how the model based approach for $\text{HR}^*$ differ from either the observed 2000 or 2023 values. 


```{r}
superset_df <- hh_df %>%
  filter(YEAR %in% c(analysis_year, baseline_year)) %>%
  filter(AGE >= minimum_age & AGE <= maximum_age) %>%
  filter(STATEFIP == 8) %>%
  mutate(MARRIED = MARST %in% c(1, 2)) %>%
  mutate(LABFORCE = LABFORCE == 2) %>%
  mutate(HSEDU = EDUC >= 6 & EDUC < 10) %>%
  mutate(COLEDU = EDUC >= 10) %>%
  mutate(TRIGEN = MULTGEN > 2) %>%
  select(
    YEAR, HEADSHIP, PERWT, AGEGROUP, HOUSINGCOST, NCHILD, MARRIED, LABFORCE,
    INCTOT, HSEDU, COLEDU, TRIGEN, HCOSTRATIO
    )

fm_anlyz_df <- superset_df %>%
  # remove individuals who dont make sense to analysis
  filter(PERWT != 0, YEAR == analysis_year) %>%
  mutate(HEADSHIP = as.integer(HEADSHIP))

design_anlyz_df <- svydesign(ids=~1, weights=~PERWT, data=fm_anlyz_df)

cf_houscost_df <- superset_df %>%
  # remove individuals who dont make sense to analysis
  filter(PERWT != 0, YEAR == baseline_year) %>%
  group_by(AGEGROUP) %>%
  summarize(
    HCOSTRATIO = weighted.median(HCOSTRATIO, PERWT, na.rm = TRUE),
    .groups = "drop") %>%
  right_join(
    superset_df %>%
      filter(YEAR == analysis_year) %>%
      select(-HCOSTRATIO),
    by = "AGEGROUP"
  )

design_anlyz_df <- svydesign(ids=~1, weights=~PERWT, data=fm_anlyz_df)

model_list <- list(
  age_lm = svyglm(
    HEADSHIP ~ AGEGROUP,
    design = design_anlyz_df, family = binomial),
  base_lm = svyglm(
    HEADSHIP ~ log(HCOSTRATIO)*AGEGROUP,
    design = design_anlyz_df, family = binomial),
  famcomp_lm = svyglm(
    HEADSHIP ~ (log(HCOSTRATIO) + MARRIED + NCHILD + TRIGEN)*AGEGROUP,
    design = design_anlyz_df, family = binomial),
  incedu_lm = svyglm(
    HEADSHIP ~ (log(HCOSTRATIO) + LABFORCE + HSEDU + COLEDU)*AGEGROUP,
    design = design_anlyz_df, family = binomial),
  full_lm = svyglm(
    HEADSHIP ~ (
      log(HCOSTRATIO) + MARRIED + NCHILD + TRIGEN + LABFORCE +
        HSEDU + COLEDU)*AGEGROUP, 
    design = design_anlyz_df, family = binomial)
  
)

model_pred_df <- bind_rows(lapply(names(model_list), function(ln){
  cf_houscost_df %>%
    mutate(NEWHR = as.vector(predict(
      model_list[[ln]], newdata = cf_houscost_df, type = "response"))) %>%
    mutate(MODEL = ln)
}))

model_pred_df %>%
  group_by(AGEGROUP, MODEL) %>%
  summarize(HR = weighted.mean(NEWHR, PERWT), .groups = "drop") %>%
  pivot_wider(names_from = MODEL, values_from = HR) %>%
  select(AGEGROUP, `Model Based` = full_lm) %>%
  left_join(co_hr_table, by = "AGEGROUP")


```

A noticeable difference between this model based approach and simply using the Headship Rates observed in 2020 is where the difference in observed and target headship rates lay. The model based approach puts more of the missingness of households into younger populations rather than older populations. 

```{r}

target_hh_df <- hh_df %>%
  filter(YEAR == analysis_year & PERWT != 0) %>%
  filter(AGE >= 15 & AGE <= maximum_age) %>%
  filter(STATEFIP == 8) %>%
  group_by(AGEGROUP) %>%
  summarize(HH = sum(PERWT*HEADSHIP)) %>%
  left_join(
    hh_df %>%
      filter(YEAR == analysis_year & PERWT != 0) %>%
      filter(AGE < minimum_age & AGE >= 15) %>%
      filter(STATEFIP == 8) %>%
      mutate(NEWHR = .04) %>%
      group_by(AGEGROUP) %>%
      summarize(NEWHH = sum(PERWT*NEWHR)) %>%
      bind_rows(
        model_pred_df %>%
          filter(MODEL == "full_lm") %>%
          group_by(AGEGROUP) %>%
          summarize(NEWHH = sum(PERWT*NEWHR))
      ),
    by = join_by(AGEGROUP)) %>%
  mutate(MISSINGHH = NEWHH - HH)

target_hh_df
```


```{r}
CO_MISSING_HH <- sum(target_hh_df$MISSINGHH)

CO_UNDERPOD <- (sum(target_hh_df$MISSINGHH)+ CO_HOUSEHOLDS)/(1-VACANCY_RATE) -
  (CO_HOUSING_UNITS- CO_SEASONAL_HOUSING - CO_UNIHABITABLE_HOUSING)
```

From these calculations we find that Colorado has `r prettyNum(round(CO_MISSING_HH ), big.mark = ",")` missing households which leads to a housing underproduction count of `r prettyNum(round(CO_UNDERPOD), big.mark = ",")` units.

To demonstrate in another way what this model is doing and show its flexibility lets pick another value for housing burden to see its impact on the housing shortage estimate. Let us say instead that we think all individuals should be paying 100% of their income on housing costs. We can place this into the model as follows.

```{r}
cf_all_income <- hh_df %>%
  filter(YEAR == analysis_year & PERWT != 0) %>%
  filter(AGE >= 15 & AGE <= maximum_age) %>%
  filter(STATEFIP == 8) %>%
  group_by(AGEGROUP) %>%
  summarize(HH = sum(PERWT*HEADSHIP)) %>%
  right_join(
    superset_df %>%
      filter(YEAR == analysis_year) %>%
      mutate(HCOSTRATIO = 1) %>%
      mutate(NEWHR = predict(
        model_list[["full_lm"]], newdata = ., type = "response")) %>%
      group_by(AGEGROUP) %>%
      summarize(NEWHH = sum(PERWT*NEWHR)),
    by = join_by(AGEGROUP)) %>%
  mutate(MISSINGHH = NEWHH - HH) %>%
  pull(MISSINGHH) %>%
  sum()
```

When we do this our model tells us that we actually have to much housing! That is if you want the citizens of Colorado to spend more of their income on housing we need to get rid of `r prettyNum(round(-cf_all_income), big.mark = ",")` units.


Alternatively, what if we wanted a scenario where individuals only spent 10% of their income on housing, what then would the housing shortage be?

```{r}
cf_ten_income <- hh_df %>%
  filter(YEAR == analysis_year & PERWT != 0) %>%
  filter(AGE >= 15 & AGE <= maximum_age) %>%
  filter(STATEFIP == 8) %>%
  group_by(AGEGROUP) %>%
  summarize(HH = sum(PERWT*HEADSHIP)) %>%
  right_join(
    superset_df %>%
      filter(YEAR == analysis_year) %>%
      mutate(HCOSTRATIO = .1) %>%
      mutate(NEWHR = predict(
        model_list[["full_lm"]], newdata = ., type = "response")) %>%
      group_by(AGEGROUP) %>%
      summarize(NEWHH = sum(PERWT*NEWHR)),
    by = join_by(AGEGROUP)) %>%
  mutate(MISSINGHH = NEWHH - HH) %>%
  pull(MISSINGHH) %>%
  sum()
```

In this case the model says we would need to add `r prettyNum(round(cf_ten_income), big.mark = ",")` units to Colorado's housing total. 